# Experience replay
replay_memory_size:   10000   # capacity of the ReplayBuffer
mini_batch_size:      32      # batch size for sampling

# ϵ-greedy schedule
epsilon_init:         0.9     # starting epsilon
epsilon_min:          0.1     # final epsilon

# Discounting & environment
gamma:                1.0     # reward discount factor
detect_range:         10      # sensor/detection radius passed to TUeMapEnv

# Target‐network updates
target_sync_freq:     20      # episodes (or steps) between hard target updates

# Dueling‐Double‐DQN specific
hidden_dim:           128     # width of the hidden layers in the DuelingDQN
lr:                   1e-3    # learning rate for the Adam optimizer
dueling_type:         average # one of [naive, average, max]